{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This assignment is made by Andreas Uldall Leonhard (cph-al141), Jacob Sørensen (cph-js284) og Yosuke Ueda (cph-yu173)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2: Pipelines and optimisations\n",
    "\n",
    "This assignment still focuses on predictive machine learning, but starts to spread\n",
    "into the area of data preprocessing and model optimisation.\n",
    "You will still be working with supervised classification tasks, but start to use more \n",
    "powerful machine learning tools from `sklearn` and the data processing library `pandas`.\n",
    "We will also be asking you to work on a completely new type of data (voice) and \n",
    "reflect on the external validity of your model.\n",
    "\n",
    "The data is based on the [Kaggle](https://kaggle.com) dataset [Gender Recognition by Voice](https://www.kaggle.com/primaryobjects/voicegender).\n",
    "\n",
    "### Part 1: Data exploration\n",
    "Your first task is to download and explore the data. What features are there?\n",
    "How are they related?\n",
    "Hand two lines that describes\n",
    "* what a frequency is\n",
    "* what the median frequency means\n",
    "* what the output label is\n",
    "\n",
    "### Part 2: Data preparation\n",
    "When we train our model we'll use a 10-fold `KFold` \n",
    "cross-validator **with** shuffling.\n",
    "Instantiate a `KFold` class and store it in a meaningful variable.\n",
    "\n",
    "When that is done, illustrate that you indeed do get 10 \n",
    "iterations of your data by iterating over the folds and simply\n",
    "printing *the shape of* the four variables: `x_train`, `y_train`, `x_test` and\n",
    "`y_test` (see \n",
    "the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) for examples on\n",
    "how to do this).\n",
    "\n",
    "Hand in\n",
    "* the instantiation of the k-fold cross-validator\n",
    "* a loop that prints the *shape* of `x_train`, `y_train`, `x_test` and `y_test`\n",
    "\n",
    "###  Part 3: Model construction\n",
    "We will use four different classification models for this task:\n",
    "1. Logistic Regression\n",
    "2. Support Vector Machine classifier\n",
    "3. Decision Tree classifier\n",
    "4. k-Nearest Neighbors classifier\n",
    "\n",
    "Instantiate the four different classifiers in *four different \n",
    "pipelines*.\n",
    "\n",
    "For now the default parameters are fine.\n",
    "\n",
    "Hand in \n",
    "* the code for constructing the four pipelines\n",
    "* one line of text per model describing how you think the classifier will perform, given the data type you are working with (voice)\n",
    "\n",
    "## Part 4: Model validation\n",
    "Now the time comes to train and validate your model.\n",
    "This training and testing **should happen for all four models**.\n",
    "The easiest way to do this is to use the `cross_val_score` \n",
    "function from `sklearn` once for all the four models.\n",
    "The code should look something like this:\n",
    "```python\n",
    "pipeline1 = ...\n",
    "pipeline2 = ...\n",
    "pipeline3 = ...\n",
    "pipeline4 = ...\n",
    "my_kfold_validator = ...\n",
    "for model in ... :\n",
    "    score = cross_val_score(model, ...)\n",
    "    print(score)\n",
    "```\n",
    "\n",
    "Hand in\n",
    "* a list per model (four lists in total) of 10 values each, showing the scores of the 10 folds,\n",
    "* at least one paragraph of text that describes what the 'score' means\n",
    "* at least one paragraph of text that describes why the scores are different\n",
    "\n",
    "## Part 5: Model optimisation: scaling\n",
    "On the website of the [Gender Recognition by Voice](https://www.kaggle.com/primaryobjects/voicegender) dataset, they say\n",
    "we can do better. So let's try!\n",
    "\n",
    "One thing that's very easy to do is to use a \n",
    "[StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "It's particularly easy, because it fits right into your existing\n",
    "pipelines. So simply add four (separate!) instances of the\n",
    "`StandardScaler` to the pipelines, one for each pipeline.\n",
    "\n",
    "Now repeat the above validation code, where you run the \n",
    "`cross_val_score` for *each* of the four pipelines. But this \n",
    "time the `StandardScaler` is included in the pipeline.\n",
    "\n",
    "Hand in\n",
    "* the code for your new pipelines that includes the `StandardScaler`)\n",
    "* at least one line of text that describes what scaling actually is\n",
    "* the **mean** of the 10 scores of the four models (this time it's only **one** number per model\n",
    "* at least two lines of text describing which model performed well, and whether this aligned with your expectation from part 3\n",
    "\n",
    "## Part 6: Manual Hyperparameter Tuning\n",
    "\n",
    "For the fourth classifier in this project -- namely kNN -- conduct a manual search for the best value of $k$ (the hyperparameter ´n_neighbors´), that yields the highest score.\n",
    "\n",
    "That means:\n",
    "\n",
    "  1. choosing a value (positive integer >= 1), \n",
    "  2. putting it into the model, \n",
    "  3. (re-)training the kNN model, and \n",
    "  4. calculating the score. \n",
    "  5. Then try 1)-4) all over again. \n",
    "\n",
    "Do these steps at least 10 times to find a good value of the hyperparameter.\n",
    "\n",
    "Pleas, hand in:\n",
    "\n",
    "* A list of hyperparameter values, plus the scores, from the 10 times you changed the hyperparameter. The scores should be the **mean** from your 10-fold cross validation runs\n",
    "* A paragraph reflecting on why the value you found for `n_neighbors` -- for the highest score -- has that value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"voice.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...    centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...    0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...    0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...    0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...    0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...    0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3168"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your first task is to download and explore the data. What features are there? How are they related? Hand two lines that describes\n",
    "\n",
    "what a frequency is\n",
    "what the median frequency means\n",
    "what the output label is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what a frequency is \n",
    "### what the median frequency means\n",
    "### what the output label is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The columns in the dataset describes the statistics on how the data is distributed. The data content is an analysis of the acoustic properties of voices. \n",
    "\n",
    "### Frequency is a number of repeating occurencies of an event. \n",
    "### The Median frequency is the middelvalue of the amplitude of voices\n",
    "### The output label is whether it is a male or female. In the dataset the label is the column marked label.  \n",
    "\n",
    "### The frequency is showing how frequent a data is appearing, and the median indicates the middelvalue between minimum and maximum values. The last column is the output label which is the labeling of gender - male or female. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 0:20].values\n",
    "y = df['label']\n",
    "label = LabelEncoder()\n",
    "y = label.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfolder = KFold(10, shuffle=True)\n",
    "kfolder.get_n_splits(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=None, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "print(kfolder) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation of k fold with 10-fold (groups) and shuffling set to boolean true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (2851, 20) (317, 20) (2851,) (317,)\n",
      "2 (2851, 20) (317, 20) (2851,) (317,)\n",
      "3 (2851, 20) (317, 20) (2851,) (317,)\n",
      "4 (2851, 20) (317, 20) (2851,) (317,)\n",
      "5 (2851, 20) (317, 20) (2851,) (317,)\n",
      "6 (2851, 20) (317, 20) (2851,) (317,)\n",
      "7 (2851, 20) (317, 20) (2851,) (317,)\n",
      "8 (2851, 20) (317, 20) (2851,) (317,)\n",
      "9 (2852, 20) (316, 20) (2852,) (316,)\n",
      "10 (2852, 20) (316, 20) (2852,) (316,)\n"
     ]
    }
   ],
   "source": [
    "i = 0;\n",
    "for train_index, test_index in kfolder.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    i=i+1\n",
    "    print(i, x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above cell shows that we got 10 iterations over the folds. This is illustrated by the 10 lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05978098 0.06424127 0.03202691 ... 0.0078125  0.         0.        ]\n",
      " [0.06600874 0.06731003 0.04022873 ... 0.0546875  0.046875   0.05263158]\n",
      " [0.0773155  0.08382942 0.03671846 ... 0.015625   0.0078125  0.04651163]\n",
      " ...\n",
      " [0.14205626 0.09579843 0.18373124 ... 2.9375     2.9296875  0.19475862]\n",
      " [0.14365874 0.09062826 0.18497617 ... 3.59375    3.5859375  0.31100218]\n",
      " [0.16550895 0.09288354 0.18304392 ... 0.5546875  0.546875   0.35      ]] [[0.16051433 0.07676688 0.14433678 ... 0.5390625  0.53125    0.28393665]\n",
      " [0.17124697 0.07487157 0.15280665 ... 0.5703125  0.5625     0.1383547 ]\n",
      " [0.17020985 0.07202301 0.1460039  ... 0.9140625  0.90625    0.17155172]\n",
      " ...\n",
      " [0.13462555 0.08440291 0.15453076 ... 4.1640625  4.15625    0.10213033]\n",
      " [0.14973093 0.08285205 0.1809322  ... 6.03125    5.828125   0.3657004 ]\n",
      " [0.1785725  0.04667868 0.1643883  ... 6.1484375  6.         0.10129123]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train , x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Model construction\n",
    "Logistic Regression\n",
    "Support Vector Machine classifier\n",
    "Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = svm.SVC()\n",
    "model_dt = tree.DecisionTreeClassifier()\n",
    "model_lr = LogisticRegression()\n",
    "model_knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([('logisticModel',model_lr)])\n",
    "pipeline_svm = Pipeline([('svm',model_svm)])\n",
    "pipeline_dt = Pipeline([('decision tree',model_dt)])\n",
    "pipeline_knn = Pipeline([('knn',model_knn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The performance of pipeline with logistic regression will perform good, because the data set is only divided in two categories. The data will probably be placed above and under the classifier. \n",
    "### The performance of the pipeline using the svm-model will likewise perform good,if we choose a linear kernel then we will effectively have the same situation as above.\n",
    "### The performance of the model using the decision tree will depend on the depth of the tree, but we predict this model will also perform well.\n",
    "### The performance of the model using the KNN ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90909091 0.91958042 0.87719298 0.9122807  0.93684211 0.90526316\n",
      " 0.88421053 0.91578947 0.91578947 0.8877193 ]\n",
      "[0.69230769 0.76223776 0.75087719 0.70526316 0.71578947 0.6877193\n",
      " 0.72280702 0.73684211 0.75087719 0.74736842]\n",
      "[0.95454545 0.97902098 0.97192982 0.96140351 0.96491228 0.96491228\n",
      " 0.95789474 0.96491228 0.96491228 0.96140351]\n",
      "[0.74475524 0.7027972  0.68070175 0.75438596 0.72631579 0.70526316\n",
      " 0.73684211 0.72982456 0.70175439 0.75789474]\n"
     ]
    }
   ],
   "source": [
    "for xmodel in [pipeline_lr, pipeline_svm, pipeline_dt, pipeline_knn]:\n",
    "    score = cross_val_score(xmodel,x_train, y_train, cv=kfolder)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The closer the score is to 1 the better the model is at predicting difference between male and female. \n",
    "### Our intuition tells us that the difference between the models is due to the default parameters applied to each model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datascale = StandardScaler().fit_transform(x_train)\n",
    "pipeline_lr = Pipeline([('standardscaler',StandardScaler()),('logisticModel',model_lr)])\n",
    "pipeline_svm = Pipeline([('standardscaler',StandardScaler()),('svm',model_svm)])\n",
    "pipeline_dt = Pipeline([('standardscaler',StandardScaler()),('decision tree',model_dt)])\n",
    "pipeline_knn = Pipeline([('standardscaler',StandardScaler()),('knn',model_knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logisticModel', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95454545 0.98251748 0.97894737 0.96842105 0.95789474 0.97894737\n",
      " 0.9754386  0.95438596 0.97192982 0.98245614]\n",
      "[0.97552448 0.98951049 0.99298246 0.98596491 0.96491228 0.98245614\n",
      " 0.97894737 0.98245614 0.98245614 0.9754386 ]\n",
      "[0.95104895 0.97902098 0.95087719 0.96842105 0.96491228 0.97192982\n",
      " 0.95087719 0.97894737 0.96140351 0.95438596]\n",
      "[0.97902098 0.98951049 0.97192982 0.9754386  0.97192982 0.95789474\n",
      " 0.97192982 0.97894737 0.96491228 0.97192982]\n"
     ]
    }
   ],
   "source": [
    "for xmodel in [pipeline_lr, pipeline_svm, pipeline_dt, pipeline_knn]:\n",
    "    score = cross_val_score(xmodel,x_train, y_train, cv=kfolder)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Model optimisation: scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling is to normalize the data so all the values are in the same range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9716071647650596\n",
      "0.9817629738682371\n",
      "0.9614329530119005\n",
      "0.9737001594896333\n"
     ]
    }
   ],
   "source": [
    "for xmodel in [pipeline_lr, pipeline_svm, pipeline_dt, pipeline_knn]:\n",
    "    score = cross_val_score(xmodel,x_train, y_train, cv=kfolder)\n",
    "    score_avg = sum(score)\n",
    "    print(score_avg/10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The average score show that Support Vector Machine was the model that performed best using scaled data. This aligned pretty good for our expectation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_knn = Pipeline([('standardscaler',StandardScaler()),('knn',model_knn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758041958041959\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(pipeline_knn,x_train, y_train, cv=kfolder)\n",
    "score_avg = sum(score)\n",
    "print(score_avg/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Manual Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100   0.9354778554778556\n",
      "600   0.8516783216783217\n",
      "150   0.9246153846153847\n",
      "50   0.9446129309287205\n",
      "30   0.9568617347564716\n",
      "15   0.9642264752791068\n",
      "5   0.974054717212612\n",
      "1   0.9754569991412098\n",
      "2   0.9747564715985769\n",
      "4   0.9733468286099864\n",
      "3   0.9730045393203289\n"
     ]
    }
   ],
   "source": [
    "arr=[100,600,150,50,30,15,5,1,2,4,3]\n",
    "\n",
    "def tryvalidate(u):\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=u)\n",
    "    pipeline_knn = Pipeline([('standardscaler',StandardScaler()),('knn',model_knn)])\n",
    "    score = cross_val_score(pipeline_knn,x_train, y_train, cv=kfolder)\n",
    "    score_avg = sum(score)\n",
    "    print(u  , \" \" , score_avg/10)\n",
    "    return\n",
    " \n",
    "\n",
    "for a in arr:\n",
    "    tryvalidate(a)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9274260826892406"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9274260826892406"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
